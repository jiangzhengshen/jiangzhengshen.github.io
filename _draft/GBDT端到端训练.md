
GBDT的特性：
1. 增量训练，online learning，逐渐加树。各棵树的输入特征可以漂移，
2. 输出的是一个标量，可导只是近似的
3. 使用叶节点id可以做到多维输出，但输出是二值的向量，导致：
  - 最主要的：无法作为真值去训练GBDT
  - 二值向量对输入不可导（或导数含义模糊）
  - loss对二值向量的导数不易求
4. 可以使用MultiGBDT输出实值向量

参数搜索：
1. 单次训练有一定代价
2. 采样次数不能太多，至多几百次
3. 参数空间不能太大
排除。

目标传播：
1. 多步训练，步数往往上百，单步性能不能太低
2. 各层输出会随训练漂移
3. 反向学习器需要随正向学习器变动
4. 各层是可求梯度的：给定输入、输出和真值，可以求出更优的输入

1. mGBDT
  - 需要使用MultiGBDT，不能替换为普通的GBDT：无法输出向量，叶节点无法作为真值
  - 各层学习率等参数需要精细调整
2. [next] GBDT2NN/DeepGBM
  - GBDT2NN使得GBDT输出的标量可以直接对输入求梯度
  - 缺点是每一棵树的训练都需要重新GBDT2NN，代价比较高
3. [working] 直接拟合GBDT的残差，然后用新一棵树distill：不会过拟合的原因，一是线性模型，而是数据量小
  - 226-10-1结构预估ETA
  - 226-10-1结构预估残差，gbdt多轮重新训练
  - 226维精简到10个，10-10-1结构
  - 更改预估logSp/sp/eta和损失函数
  - GBDT每棵树distill残差预估模型
4. [todo] 多分类GBDT，输出各类别概率
